# AI Chatbot with Terraform PR Automation

An intelligent chatbot powered by Vertex AI that collects BigQuery dataset requirements through natural language conversation and automatically generates Infrastructure-as-Code Pull Requests.

## ğŸ—ï¸ Architecture

Event-driven architecture using:
- **Frontend**: Simple HTML/CSS/JS chat interface
- **Backend**: FastAPI on Cloud Run (handles conversations and Vertex AI)
- **Worker**: Cloud Run Job (performs Git operations and PR creation)
- **Message Bus**: Cloud Pub/Sub (decouples chat from Git operations)
- **AI**: Vertex AI (Gemini 1.5 Flash for entity extraction)
- **State**: Firestore (conversation and request tracking)

## ğŸš€ Quick Start

### Prerequisites

1. **GCP Project**: `helpful-charmer-485315-j7`
2. **GitHub Personal Access Token** with `repo` permissions
3. **Enabled APIs**:
   - Cloud Run
   - Vertex AI
   - Pub/Sub
   - Firestore
   - Secret Manager

### Initial Setup

```bash
# 1. Clone the repository
git clone https://github.com/AmeerHossam/Chatbot.git
cd chatbot

# 2. Set up GCP environment
./scripts/setup_gcp.sh

# 3. Create GitHub PAT and store in Secret Manager
echo -n "YOUR_GITHUB_TOKEN" | gcloud secrets create github-pat \
  --data-file=- \
  --project=helpful-charmer-485315-j7

# 4. Deploy infrastructure
cd terraform
terraform init
terraform apply -var="project_id=helpful-charmer-485315-j7"

# 5. Deploy services
./scripts/deploy.sh
```

### Local Development

```bash
# Backend
cd backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn main:app --reload --port 8080

# Worker (in another terminal)
cd worker
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python main.py
```

## ğŸ“– Usage

### Via API

```bash
# Start conversation
curl -X POST https://YOUR_BACKEND_URL/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Create a BigQuery dataset named analytics_data in us-central1",
    "session_id": "user-123"
  }'

# Bot will ask follow-up questions for missing fields
# Continue the conversation until all fields are collected
```

### Via Web Interface

Open `frontend/index.html` in your browser or navigate to the deployed Cloud Run URL.

**Example conversation:**
```
User: I need a dataset for marketing analytics
Bot:  I can help! What should we name this dataset?

User: marketing_prod
Bot:  Got it! Which GCP region should it be in?

User: us-central1
Bot:  Perfect! What labels should I add? (e.g., env:prod, team:marketing)

User: env:production, team:marketing, cost-center:mk001
Bot:  Almost there! Which service account should own this dataset?

User: sa-marketing@helpful-charmer-485315-j7.iam.gserviceaccount.com
Bot:  âœ… Creating your Pull Request...
      ğŸ”— https://github.com/AmeerHossam/Chatbot/pull/42
      
      Your dataset will be created once the PR is reviewed and merged!
```

## ğŸ”§ Configuration

### Required Fields

The chatbot collects these 4 required fields:

1. **Dataset Name**: Valid BigQuery dataset identifier (`[a-z0-9_]+`)
2. **Location**: GCP region (e.g., `us-central1`, `eu`, `asia-northeast1`)
3. **Labels**: Key-value pairs (e.g., `env:prod, team:data`)
4. **Service Account**: Email of service account for dataset ownership

### Terraform Output

Generated files follow this structure:

```hcl
# datasets/marketing_prod.tf
resource "google_bigquery_dataset" "marketing_prod" {
  dataset_id = "marketing_prod"
  location   = "us-central1"
  
  labels = {
    env         = "production"
    team        = "marketing"
    cost-center = "mk001"
  }
  
  access {
    role          = "OWNER"
    user_by_email = "sa-marketing@helpful-charmer-485315-j7.iam.gserviceaccount.com"
  }
}
```

## ğŸ§ª Testing

```bash
# Run backend tests
cd backend
pytest tests/ -v

# Run worker tests
cd worker
pytest tests/ -v

# End-to-end test
python scripts/test_e2e.py
```

## ğŸ“Š Monitoring

View logs in Cloud Console:
```bash
# Backend logs
gcloud run services logs read chatbot-backend --project=helpful-charmer-485315-j7

# Worker logs
gcloud run jobs logs read git-worker --project=helpful-charmer-485315-j7
```

## ğŸ”’ Security

- âœ… GitHub PAT stored in Secret Manager (never in code)
- âœ… Service accounts use least-privilege IAM
- âœ… Input validation prevents injection attacks
- âœ… All PRs require manual review before merge
- âœ… Cloud Run services use private networking

## ğŸ“ Project Structure

```
chatbot/
â”œâ”€â”€ backend/              # FastAPI service
â”‚   â”œâ”€â”€ main.py          # API endpoints
â”‚   â”œâ”€â”€ vertex_ai.py     # Vertex AI integration
â”‚   â”œâ”€â”€ state_manager.py # Firestore state
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ worker/              # Git automation worker
â”‚   â”œâ”€â”€ main.py          # Pub/Sub handler
â”‚   â”œâ”€â”€ git_operations.py
â”‚   â”œâ”€â”€ terraform_generator.py
â”‚   â”œâ”€â”€ github_api.py
â”‚   â””â”€â”€ templates/       # Terraform templates
â”œâ”€â”€ terraform/           # Infrastructure as Code
â”‚   â”œâ”€â”€ backend_service.tf
â”‚   â”œâ”€â”€ worker_service.tf
â”‚   â”œâ”€â”€ pubsub.tf
â”‚   â””â”€â”€ ...
â”œâ”€â”€ frontend/            # Chat UI
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ styles.css
â”‚   â””â”€â”€ app.js
â””â”€â”€ scripts/             # Deployment scripts
    â”œâ”€â”€ setup_gcp.sh
    â””â”€â”€ deploy.sh
```

## ğŸš¦ Roadmap

- [x] MVP: Single dataset type support
- [ ] Multi-resource support (GCS buckets, Pub/Sub topics)
- [ ] Slack/Teams integration
- [ ] Approval workflows in chat
- [ ] Cost estimation before PR creation
- [ ] Rollback capabilities

## ğŸ“„ License

MIT

## ğŸ¤ Contributing

PRs welcome! Please run tests before submitting.

---

**Built with â¤ï¸ using Vertex AI and Google Cloud Platform**
